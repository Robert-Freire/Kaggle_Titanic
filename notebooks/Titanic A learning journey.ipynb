{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titanic. A learning journey\n",
    "\n",
    "## Introduction\n",
    "This is a mix that I'm learning from different Titanic noteboks. The main inspiratiors are\n",
    "\n",
    "* [Titanic Survival Predictions (Beginner)](https://www.kaggle.com/nadintamer/titanic-survival-predictions-beginner)\n",
    "* [A Data Science Framework: To Achieve 99% Accuracy](https://www.kaggle.com/ldfreeman3/a-data-science-framework-to-achieve-99-accuracy)\n",
    "\n",
    "Contents: Import Necessary Libraries Read In and Explore the Data Data Analysis Data Visualization Cleaning Data Choosing the Best Model Creating Submission File Any and all feedback is welcome!\n",
    "\n",
    "## Table of Contents\n",
    "1. [Define the problem](#ch1)\n",
    "1. [Read the data](#ch2)\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"ch1\"></a>\n",
    "\n",
    "## 1. Define the problem\n",
    "\n",
    "First thing first. What we are trying to do? \n",
    "\n",
    "Titanic. Belfast 1912. The largest ship ever made was struck by an iceberg and sank in his maiden vollage. Safety deficencies caused that more tan 1,500 of the 2,224. Our task is guess if a passenger will survive or not.\n",
    "\n",
    "Well, let's do it \n",
    "\n",
    "<a id=\"ch2\"></a>\n",
    "\n",
    "\n",
    "## 2. Read the data\n",
    "\n",
    "To start we begin reading and exploring the data \n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data analysis libraries \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#visualization libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "#import train and test CSV files\n",
    "train = pd.read_csv(\"../input/train.csv\")\n",
    "test = pd.read_csv(\"../input/test.csv\")\n",
    "\n",
    "#take a look at the training data\n",
    "print (train.info())\n",
    "train.describe(include=\"all\")\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A quick lock to the content\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Where are missing values\n",
    "print(pd.isnull(train).sum())\n",
    "print(pd.isnull(test).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test.Parch.unique())\n",
    "print(train.Parch.unique())\n",
    "\n",
    "print(test.Embarked.unique())\n",
    "print(train.Embarked.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data recap\n",
    "\n",
    "   Well, after doig a first look to the data. What we can say?\n",
    "\n",
    "   * PassengerId: Id of the passenger, doesn't seems relevant\n",
    "   * Survived: What we want to know (0/1)\n",
    "   * Pclass: A proxy for SES(Socio-Economic status) (1/2/3). \n",
    "   * Name: String with the name. Could we extract some information from here? \n",
    "   * Sex: Descriptior of the sex (male/female)\n",
    "   * Age: Age of the person\n",
    "   * SibSp: Number of siblings spouses abroad  (0- 8)\n",
    "   * Parch: Number of parent children abroad (0 - 9)\n",
    "   * Ticket: String Id of the ticket\n",
    "   * Fare: Passenger Fare\n",
    "   * Cabin: Cabin used. A lot of nulls\n",
    "   * Embark: Port of embarkation (C = Cherbourg, Q = Queenstown, S = Southampton)\n",
    "  \n",
    "      \n",
    "\n",
    "   First thoughts\n",
    "\n",
    "   * PClass is a integer but could make sense to tranform to a category?\n",
    "   * Name + SibSp + Parch + ticket + cabin. Could be used to identify families? \n",
    "\n",
    "# discover correlations\n",
    "  \n",
    "    First we will try to discover correlations between values and result\n",
    "\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for x in train:\n",
    "    if ((x != \"Survived\") and (train[x].unique().size <=10)):\n",
    "        print (x, \": \", train[x].unique().size)\n",
    "        print (train[[\"Survived\",x]].groupby(x, as_index=False).agg(['count', 'mean']))\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, this is interesting for what it says and for what is missig.\n",
    "Class, sex are very imoportant\n",
    "also it seems that there are a correlation between size of the family (Parch, sibSp) and probabilities of supervivence\n",
    "what is missing is the age, as is provided is not very useful. We will copy the way that is arranged in the notebook of LD Freeman, and by the way, it seems that he is also doing a interesting thing as is extract the Title form the name. Ok, let's do it "
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in data_cleaner:    \n",
    "    #Discrete variables\n",
    "    dataset['FamilySize'] = dataset ['SibSp'] + dataset['Parch'] + 1\n",
    "\n",
    "    dataset['IsAlone'] = 1 #initialize to yes/1 is alone\n",
    "    dataset['IsAlone'].loc[dataset['FamilySize'] > 1] = 0 # now update to no/0 if family size is greater than 1\n",
    "\n",
    "    #quick and dirty code split title from name: http://www.pythonforbeginners.com/dictionary/python-split\n",
    "    dataset['Title'] = dataset['Name'].str.split(\", \", expand=True)[1].str.split(\".\", expand=True)[0]\n",
    "\n",
    "\n",
    "    #Continuous variable bins; qcut vs cut: https://stackoverflow.com/questions/30211923/what-is-the-difference-between-pandas-qcut-and-pandas-cut\n",
    "    #Fare Bins/Buckets using qcut or frequency bins: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.qcut.html\n",
    "    dataset['FareBin'] = pd.qcut(dataset['Fare'], 4)\n",
    "\n",
    "    #Age Bins/Buckets using cut or value bins: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.cut.html\n",
    "    dataset['AgeBin'] = pd.cut(dataset['Age'].astype(int), 5)\n",
    "\n",
    "\n",
    "    \n",
    "#cleanup rare title names\n",
    "#print(data1['Title'].value_counts())\n",
    "stat_min = 10 #while small is arbitrary, we'll use the common minimum in statistics: http://nicholasjjackson.com/2012/03/08/sample-size-is-10-a-magic-number/\n",
    "title_names = (data1['Title'].value_counts() < stat_min) #this will create a true false series with title name as index\n",
    "\n",
    "#apply and lambda functions are quick and dirty code to find and replace with fewer lines of code: https://community.modeanalytics.com/python/tutorial/pandas-groupby-and-python-lambda-functions/\n",
    "data1['Title'] = data1['Title'].apply(lambda x: 'Misc' if title_names.loc[x] == True else x)\n",
    "print(data1['Title'].value_counts())\n",
    "print(\"-\"*10)\n",
    "\n",
    "\n",
    "#preview data again\n",
    "data1.info()\n",
    "data_val.info()\n",
    "data1.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#draw a bar plot of survival by sex\n",
    "fig, saxis = plt.subplots(2, 3,figsize=(16,12))\n",
    "sns.barplot(x=\"Sex\", y=\"Survived\", data=train, ax =saxis[0,0])\n",
    "sns.barplot(x=\"Pclass\", y=\"Survived\", data=train, ax =saxis[0,1])\n",
    "sns.pointplot(x = 'Age', y = 'Survived',  data=train, ax = saxis[1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x=\"Pclass\", y=\"Survived\", data=train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}